{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":9339848,"sourceType":"datasetVersion","datasetId":5660092}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install streamlit -q\n!pip install pytorch-lightning\n!pip install optuna\n!pip install transformers\n!pip install arff\n!pip install torch\n!pip install scikit-learn\n!pip install matplotlib\n!pip install seaborn\n!pip install tqdm\n!pip install pyngrok","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9JCk_lYy-6L","outputId":"74a82f9c-429c-4870-d95e-46e1e6f0ae00","execution":{"iopub.status.busy":"2024-09-09T11:42:03.692095Z","iopub.execute_input":"2024-09-09T11:42:03.692497Z","iopub.status.idle":"2024-09-09T11:44:35.195070Z","shell.execute_reply.started":"2024-09-09T11:42:03.692457Z","shell.execute_reply":"2024-09-09T11:44:35.193796Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torch>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.4.0)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.4)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.2)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.4.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.11.6)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.2)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.30)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.4)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nCollecting arff\n  Downloading arff-0.9.tar.gz (4.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: arff\n  Building wheel for arff (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for arff: filename=arff-0.9-py3-none-any.whl size=4950 sha256=4bf127bed71ca954c40f212b3d78e255a3d5fbb58de3ad1da32b666ca84068a5\n  Stored in directory: /root/.cache/pip/wheels/0c/39/12/4d8ff491018bce2dd9cc6034298f27399c7f4fd4063187f7be\nSuccessfully built arff\nInstalling collected packages: arff\nSuccessfully installed arff-0.9\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.2.2)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.10/site-packages (from seaborn) (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nCollecting pyngrok\n  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertModel, AdamW\nimport optuna\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Function to parse sparse ARFF format\ndef parse_arff(filename):\n    with open(filename, 'r') as file:\n        data_started = False\n        data = []\n        attributes = []\n\n        for line in file:\n            line = line.strip()\n            if line.lower().startswith('@attribute'):\n                attributes.append(line.split()[1])\n            elif line.lower() == '@data':\n                data_started = True\n            elif data_started:\n                if line:\n                    row_data = np.zeros(len(attributes))\n                    row_entries = line.strip('{}').split(',')\n                    for entry in row_entries:\n                        index, value = entry.split()\n                        row_data[int(index)] = float(value)\n                    data.append(row_data)\n        return pd.DataFrame(data, columns=attributes)\n\n# Convert feedback JSON to DataFrame\ndef feedback_to_dataframe(feedback_file, label_cols):\n    with open(feedback_file, 'r') as f:\n        feedback_data = json.load(f)\n\n    feedback_texts = [entry[\"text\"] for entry in feedback_data]\n    feedback_labels = [entry[\"labels\"] for entry in feedback_data]\n    \n    df_feedback = pd.DataFrame(feedback_labels, columns=label_cols)\n    df_feedback['combined_text'] = feedback_texts\n\n    return df_feedback\n\n# Merge feedback with original dataset\ndef merge_feedback_with_dataset(original_file, feedback_file, output_file, label_cols):\n    df_original = pd.read_csv(original_file)\n    df_feedback = feedback_to_dataframe(feedback_file, label_cols)\n    df_combined = pd.concat([df_original, df_feedback], ignore_index=True)\n    df_combined.to_csv(output_file, index=False)\n    print(f\"Merged dataset saved to {output_file}\")\n\n# Load and parse the ARFF file\nfile_path = '/kaggle/input/news-papers/20ng-desc.arff'\ndf_original = parse_arff(file_path)\n\n# Identify feature columns and label columns\nfeature_cols = df_original.columns[:-20]  # Assuming the last 20 columns are labels\nlabel_cols = df_original.columns[-20:]\n\n# Combine features into a single text column\ndf_original['combined_text'] = df_original[feature_cols].astype(str).agg(' '.join, axis=1)\n\n# Save original dataset to CSV\noriginal_csv_path = 'original_data.csv'\ndf_original.to_csv(original_csv_path, index=False)\nprint(f\"Original data saved to {original_csv_path}\")\n\n# Check if feedback data exists and merge it with the original dataset\nfeedback_file = 'feedback.json'\nif os.path.exists(feedback_file):\n    merge_feedback_with_dataset(original_csv_path, feedback_file, 'combined_data.csv', label_cols)\n    df_data = pd.read_csv('combined_data.csv')\nelse:\n    df_data = df_original\n\n# Split the data\ndf_train, df_test = train_test_split(df_data, test_size=0.3, random_state=42)\ndf_test, df_valid = train_test_split(df_test, test_size=0.5, random_state=42)\n\n# Hyperparameters\nMAX_LEN = 256\nEPOCHS = 2  # Use a small number for quick testing\n\n# Tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len, target_list):\n        self.tokenizer = tokenizer\n        self.df = df\n        self.texts = list(df['combined_text'])\n        self.targets = self.df[target_list].values\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = str(self.texts[index])\n        text = \" \".join(text.split())\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n            'targets': torch.FloatTensor(self.targets[index]),\n            'text': text\n        }\n\n# Create datasets\ntrain_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, label_cols)\nvalid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, label_cols)\ntest_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, label_cols)\n\nclass BERTClassLightning(pl.LightningModule):\n    def __init__(self, num_labels, learning_rate, dropout_rate):\n        super(BERTClassLightning, self).__init__()\n        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = nn.Dropout(dropout_rate)\n        self.linear = nn.Linear(768, num_labels)\n        self.learning_rate = learning_rate\n        self.train_losses = []\n        self.val_losses = []\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.bert_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        pooled_output = outputs[1]\n        output_dropout = self.dropout(pooled_output)\n        output = self.linear(output_dropout)\n        return output\n\n    def training_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        token_type_ids = batch['token_type_ids']\n        targets = batch['targets']\n        outputs = self(input_ids, attention_mask, token_type_ids)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets)\n        self.train_losses.append(loss)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        token_type_ids = batch['token_type_ids']\n        targets = batch['targets']\n        outputs = self(input_ids, attention_mask, token_type_ids)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets)\n        self.val_losses.append(loss)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def on_train_epoch_end(self):\n        avg_loss = torch.stack(self.train_losses).mean()\n        self.log('train_loss_epoch', avg_loss, prog_bar=True, logger=True)\n        self.train_losses.clear()  # Clear the list for the next epoch\n\n    def on_validation_epoch_end(self):\n        avg_loss = torch.stack(self.val_losses).mean()\n        self.log('val_loss_epoch', avg_loss, prog_bar=True, logger=True)\n        self.val_losses.clear()  # Clear the list for the next epoch\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\ndef objective(trial):\n    # Define hyperparameters to optimize, suggested by Optuna\n    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n\n    print(f\"\\n{'='*50}\")\n    print(f\"Starting trial {trial.number}\")\n    print(f\"Hyperparameters: LR={learning_rate}, Dropout={dropout_rate}, Batch Size={batch_size}\")\n    print(f\"{'='*50}\\n\")\n\n    model = BERTClassLightning(num_labels=len(label_cols), learning_rate=learning_rate, dropout_rate=dropout_rate)\n\n    trainer = pl.Trainer(\n        max_epochs=EPOCHS,\n        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n        devices=1,\n        callbacks=[ModelCheckpoint(monitor=\"val_loss\")],\n        enable_progress_bar=False  # Disable progress bar for cleaner output\n    )\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n    val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n    trainer.fit(model, train_loader, val_loader)\n\n    best_val_loss = trainer.callback_metrics.get(\"val_loss_epoch\", float('inf'))\n\n    print(f\"\\nTrial {trial.number} completed.\")\n    print(f\"Best validation loss: {best_val_loss:.4f}\")\n    print(f\"{'='*50}\\n\")\n\n    return best_val_loss\n\ndef train_and_save_model():\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=1)  # Use a small number for quick testing\n\n    best_params = study.best_params\n    best_model = BERTClassLightning(num_labels=len(label_cols), \n                                    learning_rate=best_params['learning_rate'], \n                                    dropout_rate=best_params['dropout_rate'])\n\n    trainer = pl.Trainer(\n        max_epochs=EPOCHS,\n        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n        devices=1,\n        callbacks=[ModelCheckpoint(dirpath='checkpoints', filename='best_model', save_top_k=1, monitor='val_loss')],\n    )\n\n    train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True, num_workers=2)\n    val_loader = DataLoader(valid_dataset, batch_size=best_params['batch_size'], shuffle=False, num_workers=2)\n\n    trainer.fit(best_model, train_loader, val_loader)\n\n    # Save the entire model\n    os.makedirs('model', exist_ok=True)\n    torch.save(best_model, 'model/full_model.pt')\n    torch.save(best_model.state_dict(), 'model/model_state_dict.pt')\n    best_model.bert_model.config.save_pretrained('model')\n    tokenizer.save_pretrained('model')\n\n    return trainer, best_model\n\n# Train and save the model\ntrainer, best_model = train_and_save_model()\nprint(\"Model training and saving completed.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T11:44:38.393484Z","iopub.execute_input":"2024-09-09T11:44:38.393839Z","iopub.status.idle":"2024-09-09T12:11:29.511821Z","shell.execute_reply.started":"2024-09-09T11:44:38.393803Z","shell.execute_reply":"2024-09-09T12:11:29.510816Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Original data saved to original_data.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1874da2250a34fb095b23e29c2cccb11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"201cf0c7854e4bebaa1ae8ad5a39f01f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fa08e23f10e42688142e7cbdba92cf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ac7e742ffc54ccb852bd07b37e77650"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n[I 2024-09-09 11:45:23,570] A new study created in memory with name: no-name-e3ba0bdc-c8e7-440b-8f3a-82f0eb1d4a2f\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nStarting trial 0\nHyperparameters: LR=1.2347895816423608e-05, Dropout=0.10768605914322729, Batch Size=32\n==================================================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61277616d3c54fa79c6ba06f276bf2bd"}},"metadata":{}},{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 15. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n[I 2024-09-09 11:58:29,075] Trial 0 finished with value: 0.20135243237018585 and parameters: {'learning_rate': 1.2347895816423608e-05, 'dropout_rate': 0.10768605914322729, 'batch_size': 32}. Best is trial 0 with value: 0.20135243237018585.\n","output_type":"stream"},{"name":"stdout","text":"\nTrial 0 completed.\nBest validation loss: 0.2014\n==================================================\n\n","output_type":"stream"},{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02b38ed36b564fa08399885280797d3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Model training and saving completed.\n","output_type":"stream"}]},{"cell_type":"code","source":"label_cols_list = label_cols.tolist()\nmodel_path = '/kaggle/working/model/'\n\nwith open(\"app.py\", \"w\") as f:\n    f.write(f\"\"\"\nimport streamlit as st\nimport torch\nfrom transformers import BertTokenizer\nimport pandas as pd\nimport numpy as np\nimport torch.nn as nn\nfrom transformers import BertModel\nimport json\nfrom datetime import datetime\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Define the BERTClassLightning class\nclass BERTClassLightning(nn.Module):\n    def __init__(self, num_labels, learning_rate, dropout_rate):\n        super(BERTClassLightning, self).__init__()\n        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = nn.Dropout(dropout_rate)\n        self.linear = nn.Linear(768, num_labels)\n        self.learning_rate = learning_rate\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.bert_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        pooled_output = outputs[1]\n        output_dropout = self.dropout(pooled_output)\n        output = self.linear(output_dropout)\n        return output\n\n# Load the trained model\nmodel = torch.load(f\"{model_path}full_model.pt\", map_location=device)\nmodel.eval()\nmodel.to(device)\n\ntokenizer = BertTokenizer.from_pretrained(\"{model_path}\")\nlabel_cols = {label_cols_list}  # Now correctly defined as a list\n\nMAX_LEN = {MAX_LEN}\n\n@st.cache_resource\ndef predict_category(raw_text, threshold):\n    st.write(f\"Raw input text: {{raw_text}}\")  # Debug: Log the raw input text\n    encoded_text = tokenizer.encode_plus(\n        raw_text,\n        max_length=MAX_LEN,\n        add_special_tokens=True,\n        return_token_type_ids=True,\n        pad_to_max_length=True,\n        return_attention_mask=True,\n        return_tensors='pt',\n    )\n\n    input_ids = encoded_text['input_ids'].to(device)\n    attention_mask = encoded_text['attention_mask'].to(device)\n    token_type_ids = encoded_text['token_type_ids'].to(device)\n\n    with torch.no_grad():\n        output = model(input_ids, attention_mask, token_type_ids)\n\n    probabilities = torch.sigmoid(output).cpu().numpy()[0]\n    predicted_labels = (probabilities > threshold).astype(int)\n    \n    st.write(f\"Probabilities: {{probabilities}}\")  # Debug: Log the probabilities\n    st.write(f\"Predicted labels (binary): {{predicted_labels}}\")  # Debug: Log the predicted labels\n\n    predictions = {{label: prob for label, prob, pred in zip(label_cols, probabilities, predicted_labels) if pred == 1}}\n    st.write(f\"Predictions: {{predictions}}\")  # Debug: Log the final predictions\n\n    return predictions\n\ndef save_feedback(text_input, feedback_labels, additional_feedback):\n    feedback = {{\n        \"text\": text_input,\n        \"labels\": feedback_labels,\n        \"additional_feedback\": additional_feedback,\n        \"timestamp\": datetime.now().isoformat()\n    }}\n    \n    try:\n        with open('feedback.json', 'r+') as f:\n            data = json.load(f)\n            data.append(feedback)\n            f.seek(0)\n            json.dump(data, f, indent=4)\n    except FileNotFoundError:\n        with open('feedback.json', 'w') as f:\n            json.dump([feedback], f, indent=4)\n    \n    st.write(\"Feedback saved successfully!\")\n\ndef main():\n    st.title('Multi-Label Text Classification with BERT')\n    st.write(\"Enter text and see the model's predictions. Provide feedback to improve the model.\")\n\n    text_input = st.text_area(\"Enter Text:\")\n    \n    threshold = st.slider('Prediction Threshold', 0.0, 1.0, 0.5)  # Slider for the threshold with default value 0.5\n    st.write(f\"Current Threshold: {{threshold}}\")\n\n    if st.button('Predict'):\n        predictions = predict_category(text_input, threshold)\n        st.write(\"Predictions:\")\n        for category, probability in predictions.items():\n            st.write(f\"{{category}}: {{probability:.4f}}\")\n    else:\n        predictions = {{}}  # Initialize predictions as an empty dict if no prediction has been made\n\n    # User feedback\n    st.write(\"Provide feedback:\")\n    feedback_labels = []\n    for label in label_cols:\n        is_correct = st.checkbox(f\"Is '{{label}}' correct?\", value=label in predictions)\n        feedback_labels.append(1 if is_correct else 0)\n\n    additional_feedback = st.text_area(\"Enter additional feedback (optional):\")\n\n    if st.button('Submit Feedback'):\n        save_feedback(text_input, feedback_labels, additional_feedback)\n        st.write(\"Feedback received and saved. Thank you!\")\n\nif __name__ == '__main__':\n    main()\n\"\"\")\n\nprint(\"Streamlit app script written to app.py\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T12:11:29.513185Z","iopub.execute_input":"2024-09-09T12:11:29.513495Z","iopub.status.idle":"2024-09-09T12:11:29.525109Z","shell.execute_reply.started":"2024-09-09T12:11:29.513461Z","shell.execute_reply":"2024-09-09T12:11:29.524270Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Streamlit app script written to app.py\n","output_type":"stream"}]},{"cell_type":"code","source":"from pyngrok import ngrok\nimport subprocess\nimport time\n\nif __name__ == '__main__':\n    # Get your ngrok auth token from https://dashboard.ngrok.com/get-started/your-authtoken\n    ngrok.set_auth_token(\"2lm7kPOQQmDWCtmCCYZbF98Xstn_2S3cjTS1wfi4M6N7LJdjj\")\n\n    # Define the port\n    port = 8503\n\n    # Start ngrok tunnel\n    ngrok_tunnel = ngrok.connect(addr=port, proto=\"http\", bind_tls=True)\n    print(f\"Ngrok tunnel created: {ngrok_tunnel.public_url}\")\n\n    # Start Streamlit in the background\n    streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", str(port)])\n\n    print(f\"Streamlit app is live at: {ngrok_tunnel.public_url}\")\n\n    # Keep the app running\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        print(\"Shutting down...\")\n        ngrok.disconnect(ngrok_tunnel.public_url)\n        streamlit_process.terminate()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T12:17:28.447949Z","iopub.execute_input":"2024-09-09T12:17:28.448851Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Ngrok tunnel created: https://6582-35-196-3-183.ngrok-free.app\nStreamlit app is live at: https://6582-35-196-3-183.ngrok-free.app\n\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\n\n  You can now view your Streamlit app in your browser.\n\n  Local URL: http://localhost:8503\n  Network URL: http://172.19.2.2:8503\n  External URL: http://35.196.3.183:8503\n\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n/kaggle/working/app.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(f\"/kaggle/working/model/full_model.pt\", map_location=device)\n","output_type":"stream"}]}]}